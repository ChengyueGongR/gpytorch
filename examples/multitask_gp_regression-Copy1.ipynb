{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to perform standard (Kronecker) multitask regression with kernels.IndexKernel.\n",
    "\n",
    "This differs from the [hadamard_multitask_gp_regression example notebook](https://github.com/cornellius-gp/gpytorch/blob/master/examples/hadamard_multitask_gp_regression.ipynb) in one key way:\n",
    "- Here, we assume that we want to learn **all tasks per input**. (The kernel that we learn is expressed as a Krnoecker product of an input kernel and a task kernel).\n",
    "- In the other notebook, we assume that we want to learn one tasks per input.  For each input, we specify the task of the input that we care about. (The kernel in that notebook is the Hadamard product of an input kernel and a task kernel).\n",
    "\n",
    "Multitask regression, first introduced in [this paper](https://papers.nips.cc/paper/3189-multi-task-gaussian-process-prediction.pdf) learns similarities in the outputs simultaneously. It's useful when you are performing regression on multiple functions that share the same inputs, especially if they have similarities (such as being sinusodial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training points are every 0.1 in [0,1] (note that they're the same for both tasks)\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "\n",
    "# y1 function is sin(2*pi*x) with noise N(0, 0.04)\n",
    "train_y1 = torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2\n",
    "# y2 function is cos(2*pi*x) with noise N(0, 0.04)\n",
    "train_y2 = torch.cos(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2\n",
    "\n",
    "# Create a train_y which interleaves the two\n",
    "train_y = torch.stack([train_y1, train_y2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([train_y1, train_y2], -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel, MultitaskKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Default bounds on mean are (-1e10, 1e10)\n",
    "        self.mean_module = ConstantMean()\n",
    "        # We use the very common RBF kernel\n",
    "        self.data_covar_module = RBFKernel()\n",
    "        # We learn an IndexKernel for 2 tasks\n",
    "        # (so we'll actually learn 2x2=4 tasks with correlations)\n",
    "        self.covar_module = MultitaskKernel(self.data_covar_module, n_tasks=2, rank=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        mean_x = mean_x.repeat(2)\n",
    "        covar_x = self.covar_module(x)\n",
    "        print(covar_x.size())\n",
    "        return GaussianRandomVariable(mean_x, covar_x)\n",
    "\n",
    "# Gaussian likelihood is used for regression to give predictive mean+variance\n",
    "# and learn noise\n",
    "likelihood = GaussianLikelihood()\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 1/50 - Loss: 1.136\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 2/50 - Loss: 1.088\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 3/50 - Loss: 1.034\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 4/50 - Loss: 0.979\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 5/50 - Loss: 0.920\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 6/50 - Loss: 0.867\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 7/50 - Loss: 0.808\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 8/50 - Loss: 0.746\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 9/50 - Loss: 0.686\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 10/50 - Loss: 0.643\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 11/50 - Loss: 0.575\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 12/50 - Loss: 0.541\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 13/50 - Loss: 0.492\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 14/50 - Loss: 0.467\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 15/50 - Loss: 0.424\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 16/50 - Loss: 0.403\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 17/50 - Loss: 0.351\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 18/50 - Loss: 0.341\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 19/50 - Loss: 0.288\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 20/50 - Loss: 0.228\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 21/50 - Loss: 0.212\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 22/50 - Loss: 0.166\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 23/50 - Loss: 0.141\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 24/50 - Loss: 0.135\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 25/50 - Loss: 0.087\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 26/50 - Loss: 0.066\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 27/50 - Loss: 0.042\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 28/50 - Loss: 0.004\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 29/50 - Loss: 0.011\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 30/50 - Loss: -0.018\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 31/50 - Loss: -0.044\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 32/50 - Loss: -0.046\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 33/50 - Loss: -0.058\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 34/50 - Loss: -0.061\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 35/50 - Loss: -0.046\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 36/50 - Loss: -0.069\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 37/50 - Loss: -0.066\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 38/50 - Loss: -0.047\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 39/50 - Loss: -0.047\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 40/50 - Loss: -0.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 41/50 - Loss: -0.032\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 42/50 - Loss: -0.056\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 43/50 - Loss: -0.045\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 44/50 - Loss: -0.045\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 45/50 - Loss: -0.026\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 46/50 - Loss: -0.013\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 47/50 - Loss: -0.021\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 48/50 - Loss: -0.045\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 49/50 - Loss: -0.034\n",
      "torch.Size([200, 200])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n",
      "Iter 50/50 - Loss: -0.037\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "n_iter = 50\n",
    "for i in range(n_iter):\n",
    "    # Zero prev backpropped gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Make predictions from training data\n",
    "    # Again, note feeding duplicated x_data and indices indicating which task\n",
    "    output = model(train_x)\n",
    "    # TODO: Fix this view call!!\n",
    "    loss = -mll(output, train_y.view(-1))\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, n_iter, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([302, 302])\n",
      "torch.Size([1, 100, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([100, 100])\n",
      "torch.Size([200, 200])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5a9552a34d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mobserved_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Get mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserved_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Gardn/gpytorch/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mn_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mprecomputed_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             )\n\u001b[1;32m    121\u001b[0m             predictive_covar, covar_cache = exact_predictive_covar(\n",
      "\u001b[0;32m/mnt/c/Users/Gardn/gpytorch/gpytorch/functions/__init__.py\u001b[0m in \u001b[0;36mexact_predictive_mean\u001b[0;34m(full_covar, full_mean, train_labels, n_train, noise, precomputed_cache)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mfull_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNonLazyVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecomputed_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Gardn/gpytorch/gpytorch/lazy/lazy_variable.py\u001b[0m in \u001b[0;36mexact_predictive_mean\u001b[0;34m(self, full_mean, train_labels, n_train, noise, precomputed_cache)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mtest_train_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecomputed_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAADGCAYAAADytqj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65d222c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "f, (y1_ax, y2_ax) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "# Test points every 0.02 in [0,1]\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    test_x = torch.linspace(0, 1, 51)\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "    # Get mean\n",
    "    mean = observed_pred.mean()\n",
    "    mean = mean.view(51, 2)\n",
    "    # Get lower and upper confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    lower = lower.view(51, 2)\n",
    "    upper = upper.view(51, 2)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot():\n",
    "\n",
    "    # Plot training data as black stars\n",
    "    y1_ax.plot(train_x.detach().numpy(), train_y1.detach().numpy(), 'k*')\n",
    "    # Predictive mean as blue line\n",
    "    y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "    # Shade in confidence \n",
    "    y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "    y1_ax.set_ylim([-3, 3])\n",
    "    y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    y1_ax.set_title('Observed Values (Likelihood)')\n",
    "    \n",
    "    # Plot training data as black stars\n",
    "    y2_ax.plot(train_x.detach().numpy(), train_y2.detach().numpy(), 'k*')\n",
    "    # Predictive mean as blue line\n",
    "    y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "    # Shade in confidence \n",
    "    y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "    y2_ax.set_ylim([-3, 3])\n",
    "    y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    y2_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot both tasks\n",
    "ax_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/c/Users/Gardn/gpytorch/gpytorch/lazy/lazy_variable.py\u001b[0m(419)\u001b[0;36mexact_predictive_mean\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0mtest_train_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m        \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecomputed_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> test_train_covar.size()\n",
      "torch.Size([102, 200])\n",
      "ipdb> precomputed_cache.size()\n",
      "torch.Size([200])\n",
      "ipdb> test_train_covar.matmul(precomputed_cache)\n",
      "torch.Size([1, 51, 1])\n",
      "<class 'gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable'> <class 'gpytorch.lazy.non_lazy_variable.NonLazyVariable'> torch.Size([2, 2]) torch.Size([51, 100])\n",
      "torch.Size([102, 200])\n",
      "*** RuntimeError: invalid argument 2: size '[100 x -1 x 1]' is invalid for input with 102 elements at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/THStorage.c:37\n",
      "ipdb> test_train_covar.type()\n",
      "*** AttributeError: 'LazyEvaluatedKernelVariable' object has no attribute 'type'\n",
      "ipdb> test_train_covar.evaluate_kernel()\n",
      "<gpytorch.lazy.kronecker_product_lazy_variable.KroneckerProductLazyVariable object at 0x7f65782705c0>\n",
      "ipdb> test_train_covar.evaluate_kernel().size()\n",
      "torch.Size([102, 200])\n",
      "ipdb> test_train_covar.evaluate_kernel().matmul(precomputed_cache)\n",
      "*** RuntimeError: invalid argument 2: size '[100 x -1 x 1]' is invalid for input with 102 elements at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/THStorage.c:37\n",
      "ipdb> precomputed_cache\n",
      "tensor([  1.8239,   6.4924,   2.6997,   3.9083,   2.8961,   3.0227,\n",
      "         -0.7524,  -5.1518,   4.5345,  -9.1873,  13.9776,   1.4692,\n",
      "         -4.4616,  -4.4318, -10.2847,  -2.9738,  -9.6250,  -4.4607,\n",
      "         -1.2265,   2.4647, -10.2693,  -0.9309,   4.8792,  -2.0894,\n",
      "        -11.9881,   2.7099,   7.9998,   5.5393,   5.1729,   4.7122,\n",
      "          3.3955,  -2.7528, -12.2481,   3.9812,   7.6651,  -0.1288,\n",
      "         -4.8527,  -8.0323,   4.4472,   1.2725,  -4.5845,   9.1784,\n",
      "          1.3406, -10.6532,   9.0421,   6.7302,  -4.2736,   5.8367,\n",
      "          1.6034,   1.8395,  -0.9872,   0.4332,  -6.7556,  -6.0371,\n",
      "          4.2923,   6.2635,  -5.8440,  -0.3454,   3.5799,   7.9585,\n",
      "          7.2490,   2.7149,  -2.2463,   2.9664,  -2.4104,  -7.4024,\n",
      "          3.8021,   3.7755,   1.9511,  -8.2397,   7.3153,   2.0973,\n",
      "          2.8246,   5.2462,   0.4172,  -7.1835,  -0.4115, -15.2332,\n",
      "          5.7672, -11.0210,  -7.9415,  -1.9749,  13.1664,   6.6477,\n",
      "        -11.1788,  -1.6055,  -4.4245,  -7.5560,  -6.8402,   9.4170,\n",
      "         15.7049,   2.0438,   0.4013,  14.5500,  -4.8891,  -4.8682,\n",
      "         -0.3741,   2.2643,  -4.8814, -10.4372, -12.6891,   3.0193,\n",
      "         -3.7150,  -1.1355,   8.4986,   8.3475,  -5.7443,  -9.1090,\n",
      "         12.1390,  -1.2222,  -5.6607,  -2.6532,   5.8085,   7.8567,\n",
      "         -9.6275,   1.7565,   2.1321,   3.5048,  -0.4262,   4.1242,\n",
      "          7.3622,  -3.4432,  -3.4194,  -5.2326,  -1.2213,  -9.5353,\n",
      "          2.2979,  -1.5456,  19.1285,  -1.1504,   0.7481,  -0.1195,\n",
      "         -5.3617,   6.7934,  -2.8690,   6.6150, -10.8054,   7.4110,\n",
      "         -2.1866,   2.2077,  -3.7531,   1.5493,  -8.5159,  -7.1795,\n",
      "         11.4526,  -7.1840,  -3.6457,   5.2908,  -5.6076,  -2.7726,\n",
      "          5.0700,   4.6002,  -0.6902,  -7.0754,  -3.5669,  10.5452,\n",
      "          7.9178,  -5.0078,  -3.0083,   1.6128,   2.1475,  14.6456,\n",
      "         -3.0155,   4.2787,  -1.8780,  -7.9056,   7.8216,  -3.4122,\n",
      "          7.6213,  -5.4880,  10.2717,  -4.9928, -11.4404,  -0.6939,\n",
      "          7.3934,  -1.4726,  -1.1790,   9.6808,  -8.4345,  -0.7585,\n",
      "         -5.7273, -10.8547,  -1.0660,   2.5399,   5.3433,  -1.9693,\n",
      "         -3.3260,  -3.3085,   1.7363,   2.0954,  -2.9019,  -5.0859,\n",
      "         -3.5290,  -1.3876,   4.8138,   4.6645,  -6.6817,   2.7073,\n",
      "          8.3648,   4.2264])\n",
      "ipdb> precomputed_cache.size()\n",
      "torch.Size([200])\n",
      "ipdb> test_train_covar.evaluate_kernel()._matmul(precomputed_cache)\n",
      "*** RuntimeError: invalid argument 2: size '[100 x -1 x 1]' is invalid for input with 102 elements at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/THStorage.c:37\n",
      "ipdb> foo = test_train_covar.evaluate_kernel()\n",
      "ipdb> foo.lazy_vars\n",
      "(<gpytorch.lazy.interpolated_lazy_variable.InterpolatedLazyVariable object at 0x7f65b00e84e0>, <gpytorch.lazy.non_lazy_variable.NonLazyVariable object at 0x7f65b0077fd0>)\n",
      "ipdb> foo.lazy_vars[0].size()\n",
      "torch.Size([2, 2])\n",
      "ipdb> foo.lazy_vars[1].size()\n",
      "torch.Size([51, 100])\n",
      "ipdb> rhs = precomputed_cache\n",
      "ipdb> rhs.view(foo.lazy_vars[0].size(-1), -1)\n",
      "tensor([[  1.8239,   6.4924,   2.6997,   3.9083,   2.8961,   3.0227,\n",
      "          -0.7524,  -5.1518,   4.5345,  -9.1873,  13.9776,   1.4692,\n",
      "          -4.4616,  -4.4318, -10.2847,  -2.9738,  -9.6250,  -4.4607,\n",
      "          -1.2265,   2.4647, -10.2693,  -0.9309,   4.8792,  -2.0894,\n",
      "         -11.9881,   2.7099,   7.9998,   5.5393,   5.1729,   4.7122,\n",
      "           3.3955,  -2.7528, -12.2481,   3.9812,   7.6651,  -0.1288,\n",
      "          -4.8527,  -8.0323,   4.4472,   1.2725,  -4.5845,   9.1784,\n",
      "           1.3406, -10.6532,   9.0421,   6.7302,  -4.2736,   5.8367,\n",
      "           1.6034,   1.8395,  -0.9872,   0.4332,  -6.7556,  -6.0371,\n",
      "           4.2923,   6.2635,  -5.8440,  -0.3454,   3.5799,   7.9585,\n",
      "           7.2490,   2.7149,  -2.2463,   2.9664,  -2.4104,  -7.4024,\n",
      "           3.8021,   3.7755,   1.9511,  -8.2397,   7.3153,   2.0973,\n",
      "           2.8246,   5.2462,   0.4172,  -7.1835,  -0.4115, -15.2332,\n",
      "           5.7672, -11.0210,  -7.9415,  -1.9749,  13.1664,   6.6477,\n",
      "         -11.1788,  -1.6055,  -4.4245,  -7.5560,  -6.8402,   9.4170,\n",
      "          15.7049,   2.0438,   0.4013,  14.5500,  -4.8891,  -4.8682,\n",
      "          -0.3741,   2.2643,  -4.8814, -10.4372],\n",
      "        [-12.6891,   3.0193,  -3.7150,  -1.1355,   8.4986,   8.3475,\n",
      "          -5.7443,  -9.1090,  12.1390,  -1.2222,  -5.6607,  -2.6532,\n",
      "           5.8085,   7.8567,  -9.6275,   1.7565,   2.1321,   3.5048,\n",
      "          -0.4262,   4.1242,   7.3622,  -3.4432,  -3.4194,  -5.2326,\n",
      "          -1.2213,  -9.5353,   2.2979,  -1.5456,  19.1285,  -1.1504,\n",
      "           0.7481,  -0.1195,  -5.3617,   6.7934,  -2.8690,   6.6150,\n",
      "         -10.8054,   7.4110,  -2.1866,   2.2077,  -3.7531,   1.5493,\n",
      "          -8.5159,  -7.1795,  11.4526,  -7.1840,  -3.6457,   5.2908,\n",
      "          -5.6076,  -2.7726,   5.0700,   4.6002,  -0.6902,  -7.0754,\n",
      "          -3.5669,  10.5452,   7.9178,  -5.0078,  -3.0083,   1.6128,\n",
      "           2.1475,  14.6456,  -3.0155,   4.2787,  -1.8780,  -7.9056,\n",
      "           7.8216,  -3.4122,   7.6213,  -5.4880,  10.2717,  -4.9928,\n",
      "         -11.4404,  -0.6939,   7.3934,  -1.4726,  -1.1790,   9.6808,\n",
      "          -8.4345,  -0.7585,  -5.7273, -10.8547,  -1.0660,   2.5399,\n",
      "           5.3433,  -1.9693,  -3.3260,  -3.3085,   1.7363,   2.0954,\n",
      "          -2.9019,  -5.0859,  -3.5290,  -1.3876,   4.8138,   4.6645,\n",
      "          -6.6817,   2.7073,   8.3648,   4.2264]])\n",
      "ipdb> rhs.view(foo.lazy_vars[0].size(-1), -1).size()\n",
      "torch.Size([2, 100])\n",
      "ipdb> foo.lazy_vars[0].matmul(rhs.view(foo.lazy_vars[0].size(-1), -1))\n",
      "tensor([[ -75.1583,   86.9491,   -0.4090,   30.6179,   91.3965,   91.5481,\n",
      "          -49.7600, -118.3790,  134.5144, -100.6011,   97.7339,   -4.8677,\n",
      "           -1.7592,   13.6046, -173.3760,  -16.7313,  -80.2899,  -18.6967,\n",
      "          -15.3654,   54.9154,  -48.2408,  -34.6117,   23.4978,  -59.3268,\n",
      "         -128.5231,  -43.1228,   96.6733,   43.8652,  192.2973,   38.5250,\n",
      "           39.3612,  -28.3284, -161.5731,   89.6733,   55.3262,   47.3781,\n",
      "         -127.8768,  -25.5754,   28.2592,   28.9294,  -73.3227,  102.9183,\n",
      "          -49.2783, -159.0421,  174.4117,   14.2609,  -69.4331,   97.1214,\n",
      "          -25.2631,   -2.0534,   27.4532,   38.1605,  -72.4403, -112.2473,\n",
      "           16.5611,  140.0300,   -0.0268,  -40.2830,   13.5660,   91.2218,\n",
      "           88.0804,  134.8096,  -44.5820,   61.0549,  -37.8501, -131.9688,\n",
      "           95.4505,   12.5459,   75.5197, -122.5334,  148.5064,  -15.8157,\n",
      "          -55.9943,   47.2073,   58.5482,  -82.4627,  -12.7765,  -80.6811,\n",
      "           -4.5403, -115.4746, -121.3196,  -99.5431,  123.4461,   84.9710,\n",
      "          -72.1611,  -30.4960,  -68.5859,  -99.6824,  -55.4336,  109.3152,\n",
      "          135.2533,  -17.0342,  -21.9586,  134.8766,  -13.3389,  -14.2291,\n",
      "          -52.8826,   42.4938,   12.8596,  -72.9825],\n",
      "        [-102.6753,   75.3836,  -14.1288,   18.3620,   99.0582,   98.6077,\n",
      "          -58.0899, -121.2360,  144.4174,  -78.7668,   51.0336,  -13.4660,\n",
      "           20.3209,   39.2785, -163.7398,   -5.8059,  -51.2978,   -0.7488,\n",
      "          -12.9220,   55.8632,   -8.1879,  -38.3498,    4.6086,  -63.2431,\n",
      "          -99.3627,  -67.3030,   79.8727,   26.6088,  213.0606,   24.1398,\n",
      "           31.8229,  -21.3437, -139.1552,   91.4403,   30.1384,   59.5733,\n",
      "         -134.5571,    8.7152,   12.7096,   29.5595,  -68.0619,   81.6934,\n",
      "          -68.0501, -144.0537,  171.2966,  -16.2175,  -64.7928,   91.3426,\n",
      "          -39.5088,  -11.8342,   39.1235,   45.2742,  -56.0110, -109.1437,\n",
      "           -1.0579,  142.5543,   29.4495,  -48.3571,   -1.1886,   73.3010,\n",
      "           72.9735,  153.9645,  -44.1136,   60.9675,  -34.9132, -126.7830,\n",
      "           99.5290,   -3.4443,   84.0798, -110.8241,  147.7898,  -30.2506,\n",
      "          -83.8894,   32.2441,   70.7110,  -66.3171,  -13.8140,  -23.4907,\n",
      "          -34.7421,  -88.0135, -110.8192, -113.8373,   87.1039,   72.1400,\n",
      "          -33.3491,  -29.8276,  -62.9779,  -85.8539,  -34.4334,   88.4453,\n",
      "           88.9816,  -31.4961,  -29.3344,   94.3397,    8.0760,    6.8635,\n",
      "          -63.8823,   41.4257,   40.6200,  -38.1120]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> foo.lazy_vars[0].matmul(rhs.view(foo.lazy_vars[0].size(-1), -1)).size()\n",
      "torch.Size([2, 100])\n",
      "ipdb> bar = foo.lazy_vars[0].matmul(rhs.view(foo.lazy_vars[0].size(-1), -1))\n",
      "ipdb> rhs.size(-1)\n",
      "200\n",
      "ipdb> foo.lazy_vars[0].size(-1)\n",
      "2\n",
      "ipdb> bar.size()\n",
      "torch.Size([2, 100])\n",
      "ipdb> rhs.size()\n",
      "torch.Size([200])\n",
      "ipdb> bar.view(2, 200)\n",
      "*** RuntimeError: invalid argument 2: size '[2 x 200]' is invalid for input with 200 elements at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/THStorage.c:41\n",
      "ipdb> bar.view(-1, 200)\n",
      "tensor([[ -75.1583,   86.9491,   -0.4090,   30.6179,   91.3965,   91.5481,\n",
      "          -49.7600, -118.3790,  134.5144, -100.6011,   97.7339,   -4.8677,\n",
      "           -1.7592,   13.6046, -173.3760,  -16.7313,  -80.2899,  -18.6967,\n",
      "          -15.3654,   54.9154,  -48.2408,  -34.6117,   23.4978,  -59.3268,\n",
      "         -128.5231,  -43.1228,   96.6733,   43.8652,  192.2973,   38.5250,\n",
      "           39.3612,  -28.3284, -161.5731,   89.6733,   55.3262,   47.3781,\n",
      "         -127.8768,  -25.5754,   28.2592,   28.9294,  -73.3227,  102.9183,\n",
      "          -49.2783, -159.0421,  174.4117,   14.2609,  -69.4331,   97.1214,\n",
      "          -25.2631,   -2.0534,   27.4532,   38.1605,  -72.4403, -112.2473,\n",
      "           16.5611,  140.0300,   -0.0268,  -40.2830,   13.5660,   91.2218,\n",
      "           88.0804,  134.8096,  -44.5820,   61.0549,  -37.8501, -131.9688,\n",
      "           95.4505,   12.5459,   75.5197, -122.5334,  148.5064,  -15.8157,\n",
      "          -55.9943,   47.2073,   58.5482,  -82.4627,  -12.7765,  -80.6811,\n",
      "           -4.5403, -115.4746, -121.3196,  -99.5431,  123.4461,   84.9710,\n",
      "          -72.1611,  -30.4960,  -68.5859,  -99.6824,  -55.4336,  109.3152,\n",
      "          135.2533,  -17.0342,  -21.9586,  134.8766,  -13.3389,  -14.2291,\n",
      "          -52.8826,   42.4938,   12.8596,  -72.9825, -102.6753,   75.3836,\n",
      "          -14.1288,   18.3620,   99.0582,   98.6077,  -58.0899, -121.2360,\n",
      "          144.4174,  -78.7668,   51.0336,  -13.4660,   20.3209,   39.2785,\n",
      "         -163.7398,   -5.8059,  -51.2978,   -0.7488,  -12.9220,   55.8632,\n",
      "           -8.1879,  -38.3498,    4.6086,  -63.2431,  -99.3627,  -67.3030,\n",
      "           79.8727,   26.6088,  213.0606,   24.1398,   31.8229,  -21.3437,\n",
      "         -139.1552,   91.4403,   30.1384,   59.5733, -134.5571,    8.7152,\n",
      "           12.7096,   29.5595,  -68.0619,   81.6934,  -68.0501, -144.0537,\n",
      "          171.2966,  -16.2175,  -64.7928,   91.3426,  -39.5088,  -11.8342,\n",
      "           39.1235,   45.2742,  -56.0110, -109.1437,   -1.0579,  142.5543,\n",
      "           29.4495,  -48.3571,   -1.1886,   73.3010,   72.9735,  153.9645,\n",
      "          -44.1136,   60.9675,  -34.9132, -126.7830,   99.5290,   -3.4443,\n",
      "           84.0798, -110.8241,  147.7898,  -30.2506,  -83.8894,   32.2441,\n",
      "           70.7110,  -66.3171,  -13.8140,  -23.4907,  -34.7421,  -88.0135,\n",
      "         -110.8192, -113.8373,   87.1039,   72.1400,  -33.3491,  -29.8276,\n",
      "          -62.9779,  -85.8539,  -34.4334,   88.4453,   88.9816,  -31.4961,\n",
      "          -29.3344,   94.3397,    8.0760,    6.8635,  -63.8823,   41.4257,\n",
      "           40.6200,  -38.1120]])\n",
      "ipdb> foo\n",
      "<gpytorch.lazy.kronecker_product_lazy_variable.KroneckerProductLazyVariable object at 0x7f65782705c0>\n",
      "ipdb> foo.lazy_vars[1]\n",
      "<gpytorch.lazy.non_lazy_variable.NonLazyVariable object at 0x7f65b0077fd0>\n",
      "ipdb> foo.lazy_vars[1].size()\n",
      "torch.Size([51, 100])\n",
      "ipdb> rhs\n",
      "tensor([  1.8239,   6.4924,   2.6997,   3.9083,   2.8961,   3.0227,\n",
      "         -0.7524,  -5.1518,   4.5345,  -9.1873,  13.9776,   1.4692,\n",
      "         -4.4616,  -4.4318, -10.2847,  -2.9738,  -9.6250,  -4.4607,\n",
      "         -1.2265,   2.4647, -10.2693,  -0.9309,   4.8792,  -2.0894,\n",
      "        -11.9881,   2.7099,   7.9998,   5.5393,   5.1729,   4.7122,\n",
      "          3.3955,  -2.7528, -12.2481,   3.9812,   7.6651,  -0.1288,\n",
      "         -4.8527,  -8.0323,   4.4472,   1.2725,  -4.5845,   9.1784,\n",
      "          1.3406, -10.6532,   9.0421,   6.7302,  -4.2736,   5.8367,\n",
      "          1.6034,   1.8395,  -0.9872,   0.4332,  -6.7556,  -6.0371,\n",
      "          4.2923,   6.2635,  -5.8440,  -0.3454,   3.5799,   7.9585,\n",
      "          7.2490,   2.7149,  -2.2463,   2.9664,  -2.4104,  -7.4024,\n",
      "          3.8021,   3.7755,   1.9511,  -8.2397,   7.3153,   2.0973,\n",
      "          2.8246,   5.2462,   0.4172,  -7.1835,  -0.4115, -15.2332,\n",
      "          5.7672, -11.0210,  -7.9415,  -1.9749,  13.1664,   6.6477,\n",
      "        -11.1788,  -1.6055,  -4.4245,  -7.5560,  -6.8402,   9.4170,\n",
      "         15.7049,   2.0438,   0.4013,  14.5500,  -4.8891,  -4.8682,\n",
      "         -0.3741,   2.2643,  -4.8814, -10.4372, -12.6891,   3.0193,\n",
      "         -3.7150,  -1.1355,   8.4986,   8.3475,  -5.7443,  -9.1090,\n",
      "         12.1390,  -1.2222,  -5.6607,  -2.6532,   5.8085,   7.8567,\n",
      "         -9.6275,   1.7565,   2.1321,   3.5048,  -0.4262,   4.1242,\n",
      "          7.3622,  -3.4432,  -3.4194,  -5.2326,  -1.2213,  -9.5353,\n",
      "          2.2979,  -1.5456,  19.1285,  -1.1504,   0.7481,  -0.1195,\n",
      "         -5.3617,   6.7934,  -2.8690,   6.6150, -10.8054,   7.4110,\n",
      "         -2.1866,   2.2077,  -3.7531,   1.5493,  -8.5159,  -7.1795,\n",
      "         11.4526,  -7.1840,  -3.6457,   5.2908,  -5.6076,  -2.7726,\n",
      "          5.0700,   4.6002,  -0.6902,  -7.0754,  -3.5669,  10.5452,\n",
      "          7.9178,  -5.0078,  -3.0083,   1.6128,   2.1475,  14.6456,\n",
      "         -3.0155,   4.2787,  -1.8780,  -7.9056,   7.8216,  -3.4122,\n",
      "          7.6213,  -5.4880,  10.2717,  -4.9928, -11.4404,  -0.6939,\n",
      "          7.3934,  -1.4726,  -1.1790,   9.6808,  -8.4345,  -0.7585,\n",
      "         -5.7273, -10.8547,  -1.0660,   2.5399,   5.3433,  -1.9693,\n",
      "         -3.3260,  -3.3085,   1.7363,   2.0954,  -2.9019,  -5.0859,\n",
      "         -3.5290,  -1.3876,   4.8138,   4.6645,  -6.6817,   2.7073,\n",
      "          8.3648,   4.2264])\n",
      "ipdb> rhs.size()\n",
      "torch.Size([200])\n",
      "ipdb> lazy_var = foo.lazy_vars[1]\n",
      "ipdb> res = rhs\n",
      "ipdb> res = res.view(lazy_var.size(-1), -1)\n",
      "ipdb> res\n",
      "tensor([[  1.8239,   6.4924],\n",
      "        [  2.6997,   3.9083],\n",
      "        [  2.8961,   3.0227],\n",
      "        [ -0.7524,  -5.1518],\n",
      "        [  4.5345,  -9.1873],\n",
      "        [ 13.9776,   1.4692],\n",
      "        [ -4.4616,  -4.4318],\n",
      "        [-10.2847,  -2.9738],\n",
      "        [ -9.6250,  -4.4607],\n",
      "        [ -1.2265,   2.4647],\n",
      "        [-10.2693,  -0.9309],\n",
      "        [  4.8792,  -2.0894],\n",
      "        [-11.9881,   2.7099],\n",
      "        [  7.9998,   5.5393],\n",
      "        [  5.1729,   4.7122],\n",
      "        [  3.3955,  -2.7528],\n",
      "        [-12.2481,   3.9812],\n",
      "        [  7.6651,  -0.1288],\n",
      "        [ -4.8527,  -8.0323],\n",
      "        [  4.4472,   1.2725],\n",
      "        [ -4.5845,   9.1784],\n",
      "        [  1.3406, -10.6532],\n",
      "        [  9.0421,   6.7302],\n",
      "        [ -4.2736,   5.8367],\n",
      "        [  1.6034,   1.8395],\n",
      "        [ -0.9872,   0.4332],\n",
      "        [ -6.7556,  -6.0371],\n",
      "        [  4.2923,   6.2635],\n",
      "        [ -5.8440,  -0.3454],\n",
      "        [  3.5799,   7.9585],\n",
      "        [  7.2490,   2.7149],\n",
      "        [ -2.2463,   2.9664],\n",
      "        [ -2.4104,  -7.4024],\n",
      "        [  3.8021,   3.7755],\n",
      "        [  1.9511,  -8.2397],\n",
      "        [  7.3153,   2.0973],\n",
      "        [  2.8246,   5.2462],\n",
      "        [  0.4172,  -7.1835],\n",
      "        [ -0.4115, -15.2332],\n",
      "        [  5.7672, -11.0210],\n",
      "        [ -7.9415,  -1.9749],\n",
      "        [ 13.1664,   6.6477],\n",
      "        [-11.1788,  -1.6055],\n",
      "        [ -4.4245,  -7.5560],\n",
      "        [ -6.8402,   9.4170],\n",
      "        [ 15.7049,   2.0438],\n",
      "        [  0.4013,  14.5500],\n",
      "        [ -4.8891,  -4.8682],\n",
      "        [ -0.3741,   2.2643],\n",
      "        [ -4.8814, -10.4372],\n",
      "        [-12.6891,   3.0193],\n",
      "        [ -3.7150,  -1.1355],\n",
      "        [  8.4986,   8.3475],\n",
      "        [ -5.7443,  -9.1090],\n",
      "        [ 12.1390,  -1.2222],\n",
      "        [ -5.6607,  -2.6532],\n",
      "        [  5.8085,   7.8567],\n",
      "        [ -9.6275,   1.7565],\n",
      "        [  2.1321,   3.5048],\n",
      "        [ -0.4262,   4.1242],\n",
      "        [  7.3622,  -3.4432],\n",
      "        [ -3.4194,  -5.2326],\n",
      "        [ -1.2213,  -9.5353],\n",
      "        [  2.2979,  -1.5456],\n",
      "        [ 19.1285,  -1.1504],\n",
      "        [  0.7481,  -0.1195],\n",
      "        [ -5.3617,   6.7934],\n",
      "        [ -2.8690,   6.6150],\n",
      "        [-10.8054,   7.4110],\n",
      "        [ -2.1866,   2.2077],\n",
      "        [ -3.7531,   1.5493],\n",
      "        [ -8.5159,  -7.1795],\n",
      "        [ 11.4526,  -7.1840],\n",
      "        [ -3.6457,   5.2908],\n",
      "        [ -5.6076,  -2.7726],\n",
      "        [  5.0700,   4.6002],\n",
      "        [ -0.6902,  -7.0754],\n",
      "        [ -3.5669,  10.5452],\n",
      "        [  7.9178,  -5.0078],\n",
      "        [ -3.0083,   1.6128],\n",
      "        [  2.1475,  14.6456],\n",
      "        [ -3.0155,   4.2787],\n",
      "        [ -1.8780,  -7.9056],\n",
      "        [  7.8216,  -3.4122],\n",
      "        [  7.6213,  -5.4880],\n",
      "        [ 10.2717,  -4.9928],\n",
      "        [-11.4404,  -0.6939],\n",
      "        [  7.3934,  -1.4726],\n",
      "        [ -1.1790,   9.6808],\n",
      "        [ -8.4345,  -0.7585],\n",
      "        [ -5.7273, -10.8547],\n",
      "        [ -1.0660,   2.5399],\n",
      "        [  5.3433,  -1.9693],\n",
      "        [ -3.3260,  -3.3085],\n",
      "        [  1.7363,   2.0954],\n",
      "        [ -2.9019,  -5.0859],\n",
      "        [ -3.5290,  -1.3876],\n",
      "        [  4.8138,   4.6645],\n",
      "        [ -6.6817,   2.7073],\n",
      "        [  8.3648,   4.2264]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> res.size()\n",
      "torch.Size([100, 2])\n",
      "ipdb> factor = lazy_var._matmul(res)\n",
      "ipdb> factor.size()\n",
      "torch.Size([51, 2])\n",
      "ipdb> n_cols = rhs.size(-1)\n",
      "ipdb> factor.view(-1, n_cols)\n",
      "*** RuntimeError: invalid argument 2: size '[-1 x 200]' is invalid for input with 102 elements at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/THStorage.c:37\n",
      "ipdb> factor.size()\n",
      "torch.Size([51, 2])\n",
      "ipdb> n_cols\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
